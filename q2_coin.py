# -*- coding: utf-8 -*-
"""Q2_Coin.ipynb

Automatically generated by Colaboratory.
Author:Xiaomeng Yao

Simply flip the two coins simultaneously for n number of times, and decide after how many times, 
the coin showing more heads can be identified as the biased coin with 99% certainty. Assume that the 
biased coin is in the left hand and the fair coin is in the right hand. Let the flip result of the coin in the left hand to be Li. 
Since it is biased, Li=H=1 with probability 0.6, while Li=Tail=0 with probability 0.4. Let the flip result of the coin in the right hand
to be Ri, knowing it is a fair coin gives that P(Ri=H=1)=0.5 and P(Li=T=0)=0.5. Now Let Xi=Li-Ri, simultaneously flipping 
the two coins gives that P(Xi=1)=0.3,P(Xi=0)=0.5 and P(Xi=-1)=0.2. After n pairs of flips, record all the pair flips results.
if n is large enough, then Sn=sum(Xi)_1_ n will surely be greater than zero since P(Xi=1)>P(Xi=-1). Now we want to find n such 
that P(Sn>0)>0.99. Once we find n, by symmetry (the same applies to the case that the biased coin is in the right hand) the coin
that shows more heads than tails will be identified as the biased coin with 99% certainty. 

The following part is a short program to work out n. The program consists of three functions. convolv_many use convolution 
to find the distribution of Sn. prob_func returns P(Sn >0) given any n. size_func uses a binary search to work out the 
required sample size n such that P(Sn>0)>0.99. 

Note that this strategy is superior to the strategy of simply flipping one coin at a time. This is because the population itself (for both
the biased coin and the fair coin) is relatively homogeneous, By Corhan's formula large sample size will be required in this case to reject
the null hypothesis.
"""

import numpy as np

def convolve_many(arrays):
    """
    Convolve a list of 1d float arrays together, using FFTs.
    The arrays need not have the same length, but each array should
    have length at least 1.

    """
    result_length = 1 + sum((len(array) - 1) for array in arrays)

    # copy each array into a 2d array of the appropriate shape.
    rows = np.zeros((len(arrays), result_length))
    for i, array in enumerate(arrays):
        rows[i, :len(array)] = array

    # transform, take the product, and do the inverse transform
    # to get the convolution.
    fft_of_rows = np.fft.fft(rows)
    fft_of_convolution = fft_of_rows.prod(axis=0)
    convolution = np.fft.ifft(fft_of_convolution)

    # assuming real inputs, the imaginary part of the output can
    # be ignored.
    return convolution.real

def prob_func(n):
    """
    Calculate the probabilities of more heads than tails 
    """
    x = np.array([[0.2,0.5,0.3]])
    y =  np.repeat(x, repeats = n, axis=0)
    probs = convolve_many(y)
    # use symmetry to find the cumulative probabilities of more heads than tails 
    return np.sum(probs[int((len(probs)+1)/2):len(probs)])

def size_func():
    """
    Work out the trail size using a binary search
    """
    # initialise the end points 
    low=1 
    high=10000
    # binary search to find the trial size
    while high-low >1:
      trial=round((high+low)/2)
      if prob_func(trial)-0.99>0:
         high=trial
      elif prob_func(trial)-0.99<0:
         low=trial
      else:
         break
    return trial

if __name__ == '__main__':
    size_func()